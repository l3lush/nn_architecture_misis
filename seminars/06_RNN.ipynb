{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHuaydsRgOU4"
   },
   "source": [
    "# Generating names with recurrent neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Cnk2D6brgOU8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgZBUwqCgOU9"
   },
   "source": [
    "# Our data\n",
    "Датасет состоит из 8к имен, написанных латиницей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "osu_vpp9gOU-"
   },
   "outputs": [],
   "source": [
    "start_token = \" \"\n",
    "\n",
    "def read_names(path_to_file):\n",
    "    global start_token\n",
    "    \n",
    "    with open(path_to_file) as f:\n",
    "        names = f.read()[:-1].split('\\n')\n",
    "        names = [start_token + line for line in names]\n",
    "        return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "n0hiXfs8gOU_"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    names = read_names('./names')\n",
    "except FileNotFoundError:\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/names_dataset/names -nc -O names\n",
    "    names = read_names('./names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cG1kKZ7NgOU_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n samples =  7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print ('n samples = ',len(names))\n",
    "for x in names[::1000]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NBo9OREUgOVA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGzCAYAAAAxPS2EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6kklEQVR4nO3dfVwVZf7/8fcBPEdRQMHgQCGSlua9oRnlbRqIrK5pa5p5l6m1mKn7dYktFe0Gw9YsM802tS1drf2alZaJN4mbZImRdy2poVgK9tPkpBaIzO+PfTDfjqCGCx4GX8/HYx4x13XNzGemo76Zc805NsMwDAEAAFiIl6cLAAAAqCgCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDIAr8sknn8hms+mTTz7xdCmXZbPZNH78+ErdZ3nnP3LkSDVu3LhSj3MxjRs31siRI831pUuXymazaceOHVfl+N27d1f37t2vyrGA8hBgUOPt3r1b9957ryIiIlS7dm1df/31uvvuuzVv3jxPl4ZKtG3bNiUnJ+vUqVOeLqVC9u3bp+TkZB06dMjTpZRRnWsDCDCo0bZt26YOHTroq6++0pgxY/Tyyy/roYcekpeXl1588UVPl4dKtG3bNs2YMcOjAea1115TdnZ2hbbZt2+fZsyYUeGQkJ2drddee61C21TUpWpbv3691q9fX6XHBy7Fx9MFAFXpmWeeUUBAgL744gvVr1/fre/48eOeKQo1Vq1atap0/4Zh6JdfflGdOnXkcDiq9FiXY7fbPXp8gDswqNEOHjyoli1blgkvkhQcHFym7a233lJUVJTq1KmjwMBADR48WEeOHCkzbtGiRWrSpInq1Kmj2267TVu3bi0zJ6B0TsKFv71ebO7I9u3b1bt3bwUEBMjX11fdunXTp59+6jYmOTlZNptNBw4c0MiRI1W/fn0FBARo1KhROnv2bLnnc9ttt8nX11cNGjRQ165dy/zW/NFHH6lLly6qW7eu/Pz8FB8fr71795bZ129V2efx888/a8KECWrYsKH8/PzUr18/ff/997LZbEpOTjb3N2XKFElSZGSkbDZbudd+9erVatWqlRwOh1q2bKl169b9pnP67rvv1L9/f9WtW1fBwcGaNGmSCgsLy4wrbw7MihUrFBUVJT8/P/n7+6t169bm3b+lS5fqD3/4gySpR48eZt2lr43GjRvrd7/7nT7++GN16NBBderU0auvvmr2/XoOTKmzZ89q3LhxCgoKkr+/v4YPH64ff/zRbcyvr92v/Xqfl6utvDkwx48f1+jRoxUSEqLatWurbdu2euONN9zGHDp0SDabTc8//7z558jhcKhjx4764osvytQEXAx3YFCjRUREKCMjQ3v27FGrVq0uOfaZZ57R1KlTNWjQID300EP64YcfNG/ePHXt2lVffvmlGYJef/11jRs3TnfccYcmTpyob7/9Vv369VNgYKDCw8OvqM5NmzYpLi5OUVFRmj59ury8vLRkyRLddddd2rp1q2677Ta38YMGDVJkZKRSUlK0c+dO/e1vf1NwcLCee+45c8yMGTOUnJysO+64QzNnzpTdbtf27du1adMmxcTESJLefPNNjRgxQrGxsXruued09uxZLViwQJ07d9aXX35Z4QmpVXEeI0eO1Ntvv61hw4bp9ttv15YtWxQfH++2nwEDBuibb77RP/7xD73wwgtq2LChJOm6664zx/zrX//SqlWr9Mc//lF+fn566aWXNHDgQOXm5iooKOii5/Tzzz+rZ8+eys3N1YQJExQWFqY333xTmzZtuuz1SEtL05AhQ9SzZ0/znL7++mt9+umneuyxx9S1a1dNmDBBL730kv7yl7/olltukSTzv9J/3ioaMmSIxo0bpzFjxqhZs2aXPOb48eNVv359JScnKzs7WwsWLNDhw4fN4Pxb/Zbafu3nn39W9+7ddeDAAY0fP16RkZF65513NHLkSJ06dUqPPfaY2/jly5frp59+0rhx42Sz2ZSamqoBAwbo22+/rfI7WaghDKAGW79+veHt7W14e3sb0dHRxp///Gfj448/NoqKitzGHTp0yPD29jaeeeYZt/bdu3cbPj4+ZntRUZERHBxstGvXzigsLDTHLVq0yJBkdOvWzWxbsmSJIcnIyclx2+fmzZsNScbmzZsNwzCMkpIS46abbjJiY2ONkpISc9zZs2eNyMhI4+677zbbpk+fbkgyHnzwQbd93nPPPUZQUJC5vn//fsPLy8u45557jPPnz7uNLT3GTz/9ZNSvX98YM2aMW39eXp4REBBQpv1CV+M8MjMzDUnGxIkT3caNHDnSkGRMnz7dbJs9e3a519swDEOSYbfbjQMHDphtX331lSHJmDdv3iXPc+7cuYYk4+233zbbzpw5YzRt2tTt/A3DMEaMGGFERESY64899pjh7+9vFBcXX3T/77zzTpn9lIqIiDAkGevWrSu3b8SIEeZ66estKirK7fWdmppqSDLee+89s+3Ca3exfV6qtm7durm93kuv01tvvWW2FRUVGdHR0Ua9evUMl8tlGIZh5OTkGJKMoKAg4+TJk+bY9957z5BkfPDBB2WOBZSHt5BQo919993KyMhQv3799NVXXyk1NVWxsbG6/vrr9f7775vjVq1apZKSEg0aNEj/7//9P3NxOp266aabtHnzZknSjh07dPz4cT388MNucwBGjhypgICAK6oxKytL+/fv1/33368TJ06Yxz5z5ox69uyp9PR0lZSUuG3z8MMPu6136dJFJ06ckMvlkvSft0pKSko0bdo0eXm5/zEv/S08LS1Np06d0pAhQ9zO2dvbW506dTLP2ZPnUfoWzx//+Ee3cY8++miFapOkXr16qUmTJuZ6mzZt5O/vr2+//faS23344YcKDQ3Vvffea7b5+vpq7Nixlz1m/fr1debMGaWlpVW43lKRkZGKjY39zePHjh3rdgfjkUcekY+Pjz788MMrruG3+PDDD+V0OjVkyBCzrVatWpowYYJOnz6tLVu2uI2/77771KBBA3O9S5cuknTZ/x9AKd5CQo3XsWNHrVq1SkVFRfrqq6/07rvv6oUXXtC9996rrKwstWjRQvv375dhGLrpppvK3UfpPwiHDx+WpDLjatWqpRtvvPGK6tu/f78kacSIERcdU1BQ4PaXfaNGjdz6S/t+/PFH+fv76+DBg/Ly8lKLFi0ue9y77rqr3H5/f//fdgIX7K8yz+Pw4cPy8vJSZGSk27imTZtWqLbyjlV6vAvnh1zo8OHDatq0aZm3Xy73Vo70n+D19ttvKy4uTtdff71iYmI0aNAg9e7d+zfXfeG5X86Fr8169eopNDS0yh+FPnz4sG666aYygbn0LafSPzulLvX/HvgtCDC4ZtjtdnXs2FEdO3bUzTffrFGjRumdd97R9OnTVVJSIpvNpo8++kje3t5ltq1Xr16Fj3ex+Qbnz593Wy+9KzF79my1a9eu3G0uPH55NUr/eUrltyo97ptvvimn01mm38enYn89eOo8fqureaxSwcHBysrK0scff6yPPvpIH330kZYsWaLhw4eXmdx6MXXq1Kmy+i504WuzKnni/wdqFgIMrkkdOnSQJB07dkyS1KRJExmGocjISN18880X3S4iIkLSf+42/PrOxblz55STk6O2bduabaW/UV74uSQX/iZa+raGv7+/evXqdYVn5K5JkyYqKSnRvn37LhomSo8bHBxcKcetivOIiIhQSUmJcnJy3O4sHDhwoMzYikxQrWgNe/bskWEYbsf4rZ/3Yrfb1bdvX/Xt21clJSX64x//qFdffVVTp04t987Of2v//v3q0aOHuX769GkdO3ZMffr0MdsaNGhQ5nVZVFRk/nkoVZHaIiIitGvXLpWUlLjdhfn3v/9t9gOViTkwqNE2b95c7m90pfMBSt8GGDBggLy9vTVjxowy4w3D0IkTJyT9J/hcd911WrhwoYqKiswxS5cuLfMPQuk/6Onp6Wbb+fPntWjRIrdxUVFRatKkiZ5//nmdPn26TK0//PDDbz1dU//+/eXl5aWZM2eWmXdSen6xsbHy9/fXs88+q3Pnzv3Xx62K8yid+/HKK6+4tZf3Kcp169aVVDYw/rf69Omjo0eP6p///KfZdvbs2TL/H8tT+rop5eXlpTZt2kiS+Rh2Zde9aNEit/+fCxYsUHFxseLi4sy2Jk2auL0uS7e78A5MRWrr06eP8vLytHLlSrOtuLhY8+bNU7169dStW7crOR3gorgDgxrt0Ucf1dmzZ3XPPfeoefPmKioq0rZt27Ry5Uo1btxYo0aNkvSfv9CffvppJSUl6dChQ+rfv7/8/PyUk5Ojd999V2PHjtX//M//qFatWnr66ac1btw43XXXXbrvvvuUk5OjJUuWlJkD07JlS91+++1KSkrSyZMnFRgYqBUrVqi4uNhtnJeXl/72t78pLi5OLVu21KhRo3T99dfr+++/1+bNm+Xv768PPvigQufdtGlTPfHEE3rqqafUpUsXDRgwQA6HQ1988YXCwsKUkpIif39/LViwQMOGDdOtt96qwYMH67rrrlNubq7Wrl2rO++8Uy+//PJvPmZVnEdUVJQGDhyouXPn6sSJE+Zj1N98840k9zsEUVFRkqQnnnhCgwcPVq1atdS3b1/zH+ErVfoJzsOHD1dmZqZCQ0P15ptvytfX97LbPvTQQzp58qTuuusu3XDDDTp8+LDmzZundu3amXND2rVrJ29vbz333HMqKCiQw+HQXXfdVe7nFP0WRUVF6tmzpwYNGqTs7Gy98sor6ty5s/r16+dW18MPP6yBAwfq7rvv1ldffaWPP/7YfPy8VEVqGzt2rF599VWNHDlSmZmZaty4sf75z3/q008/1dy5c+Xn53dF5wNclIeefgKuio8++sh48MEHjebNmxv16tUz7Ha70bRpU+PRRx818vPzy4z/3//9X6Nz585G3bp1jbp16xrNmzc3EhISjOzsbLdxr7zyihEZGWk4HA6jQ4cORnp6epnHSg3DMA4ePGj06tXLcDgcRkhIiPGXv/zFSEtLK/fR1C+//NIYMGCAERQUZDgcDiMiIsIYNGiQsXHjRnNM6ePHP/zwg9u2F3tke/HixUb79u0Nh8NhNGjQwOjWrZuRlpbmNmbz5s1GbGysERAQYNSuXdto0qSJMXLkSGPHjh2XvLYXPkZdVedx5swZIyEhwQgMDDTq1atn9O/f38jOzjYkGbNmzXLb/qmnnjKuv/56w8vLy20/koyEhIQy53DhY8MXc/jwYaNfv36Gr6+v0bBhQ+Oxxx4z1q1bd9nHqP/5z38aMTExRnBwsGG3241GjRoZ48aNM44dO+a2/9dee8248cYbDW9vb7d9RkREGPHx8eXWdLHHqLds2WKMHTvWaNCggVGvXj1j6NChxokTJ9y2PX/+vJGYmGg0bNjQ8PX1NWJjY40DBw6Uez0uVlt5r/f8/Hxj1KhRRsOGDQ273W60bt3aWLJkiduY0seoZ8+eXeacdJHHu4Hy2AyDGVNAZSj9VFIrfDuz1WVlZal9+/Z66623NHToUE+XA8ADmAMDoFr7+eefy7TNnTtXXl5e6tq1qwcqAlAdMAcGQLWWmpqqzMxM9ejRQz4+PubjyGPHjr3ir24AYH0EGADV2h133KG0tDQ99dRTOn36tBo1aqTk5GQ98cQTni4NgAcxBwYAAFgOc2AAAIDlEGAAAIDl1Ng5MCUlJTp69Kj8/Pyq7CPGAQBA5TIMQz/99JPCwsLKfDnor9XYAHP06FGeUAAAwKKOHDmiG2644aL9NTbAlH5s9ZEjR+Tv7+/hagAAwG/hcrkUHh5+2a+fqLEBpvRtI39/fwIMAAAWc7npH0ziBQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAluPj6QIAK2n8+NpK2c+hWfGVsh8AuFZxBwYAAFgOAQYAAFgOAQYAAFgOAQYAAFhOhQJMSkqKOnbsKD8/PwUHB6t///7Kzs52G/PLL78oISFBQUFBqlevngYOHKj8/Hy3Mbm5uYqPj5evr6+Cg4M1ZcoUFRcXu4355JNPdOutt8rhcKhp06ZaunTplZ0hAACocSoUYLZs2aKEhAR99tlnSktL07lz5xQTE6MzZ86YYyZNmqQPPvhA77zzjrZs2aKjR49qwIABZv/58+cVHx+voqIibdu2TW+88YaWLl2qadOmmWNycnIUHx+vHj16KCsrSxMnTtRDDz2kjz/+uBJOGQAAWJ3NMAzjSjf+4YcfFBwcrC1btqhr164qKCjQddddp+XLl+vee++VJP373//WLbfcooyMDN1+++366KOP9Lvf/U5Hjx5VSEiIJGnhwoVKTEzUDz/8ILvdrsTERK1du1Z79uwxjzV48GCdOnVK69at+021uVwuBQQEqKCgQP7+/ld6ioAbHqMGgKr1W//9/q/mwBQUFEiSAgMDJUmZmZk6d+6cevXqZY5p3ry5GjVqpIyMDElSRkaGWrdubYYXSYqNjZXL5dLevXvNMb/eR+mY0n2Up7CwUC6Xy20BAAA10xUHmJKSEk2cOFF33nmnWrVqJUnKy8uT3W5X/fr13caGhIQoLy/PHPPr8FLaX9p3qTEul0s///xzufWkpKQoICDAXMLDw6/01AAAQDV3xQEmISFBe/bs0YoVKyqzniuWlJSkgoICczly5IinSwIAAFXkir5KYPz48VqzZo3S09N1ww03mO1Op1NFRUU6deqU212Y/Px8OZ1Oc8znn3/utr/Sp5R+PebCJ5fy8/Pl7++vOnXqlFuTw+GQw+G4ktMBAAAWU6E7MIZhaPz48Xr33Xe1adMmRUZGuvVHRUWpVq1a2rhxo9mWnZ2t3NxcRUdHS5Kio6O1e/duHT9+3ByTlpYmf39/tWjRwhzz632UjindBwAAuLZV6A5MQkKCli9frvfee09+fn7mnJWAgADVqVNHAQEBGj16tCZPnqzAwED5+/vr0UcfVXR0tG6//XZJUkxMjFq0aKFhw4YpNTVVeXl5evLJJ5WQkGDeQXn44Yf18ssv689//rMefPBBbdq0SW+//bbWrq2cJ0AAAIC1VegOzIIFC1RQUKDu3bsrNDTUXFauXGmOeeGFF/S73/1OAwcOVNeuXeV0OrVq1Sqz39vbW2vWrJG3t7eio6P1wAMPaPjw4Zo5c6Y5JjIyUmvXrlVaWpratm2rv/71r/rb3/6m2NjYSjhlAABgdf/V58BUZ3wODKoCnwMDAFXrqnwODAAAgCcQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOX4eLoA4FIaP762UvZzaFZ8pewHAFA9cAcGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYToUDTHp6uvr27auwsDDZbDatXr3ard9ms5W7zJ492xzTuHHjMv2zZs1y28+uXbvUpUsX1a5dW+Hh4UpNTb2yMwQAADVOhQPMmTNn1LZtW82fP7/c/mPHjrktixcvls1m08CBA93GzZw5023co48+ava5XC7FxMQoIiJCmZmZmj17tpKTk7Vo0aKKlgsAAGogn4puEBcXp7i4uIv2O51Ot/X33ntPPXr00I033ujW7ufnV2ZsqWXLlqmoqEiLFy+W3W5Xy5YtlZWVpTlz5mjs2LEVLRkAANQwVToHJj8/X2vXrtXo0aPL9M2aNUtBQUFq3769Zs+ereLiYrMvIyNDXbt2ld1uN9tiY2OVnZ2tH3/8sdxjFRYWyuVyuS0AAKBmqvAdmIp444035OfnpwEDBri1T5gwQbfeeqsCAwO1bds2JSUl6dixY5ozZ44kKS8vT5GRkW7bhISEmH0NGjQoc6yUlBTNmDGjis4EAABUJ1UaYBYvXqyhQ4eqdu3abu2TJ082f27Tpo3sdrvGjRunlJQUORyOKzpWUlKS235dLpfCw8OvrHAAAFCtVVmA2bp1q7Kzs7Vy5crLju3UqZOKi4t16NAhNWvWTE6nU/n5+W5jStcvNm/G4XBccfgBAADWUmVzYF5//XVFRUWpbdu2lx2blZUlLy8vBQcHS5Kio6OVnp6uc+fOmWPS0tLUrFmzct8+AgAA15YKB5jTp08rKytLWVlZkqScnBxlZWUpNzfXHONyufTOO+/ooYceKrN9RkaG5s6dq6+++krffvutli1bpkmTJumBBx4ww8n9998vu92u0aNHa+/evVq5cqVefPFFt7eIAADAtavCbyHt2LFDPXr0MNdLQ8WIESO0dOlSSdKKFStkGIaGDBlSZnuHw6EVK1YoOTlZhYWFioyM1KRJk9zCSUBAgNavX6+EhARFRUWpYcOGmjZtGo9QAwAASZLNMAzD00VUBZfLpYCAABUUFMjf39/T5eAKNX58baXs59Cs+ErZT3WrBwBqmt/67zffhQQAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACyHAAMAACynwgEmPT1dffv2VVhYmGw2m1avXu3WP3LkSNlsNreld+/ebmNOnjypoUOHyt/fX/Xr19fo0aN1+vRptzG7du1Sly5dVLt2bYWHhys1NbXiZwcAAGqkCgeYM2fOqG3btpo/f/5Fx/Tu3VvHjh0zl3/84x9u/UOHDtXevXuVlpamNWvWKD09XWPHjjX7XS6XYmJiFBERoczMTM2ePVvJyclatGhRRcsFAAA1kE9FN4iLi1NcXNwlxzgcDjmdznL7vv76a61bt05ffPGFOnToIEmaN2+e+vTpo+eff15hYWFatmyZioqKtHjxYtntdrVs2VJZWVmaM2eOW9ABAADXpiqZA/PJJ58oODhYzZo10yOPPKITJ06YfRkZGapfv74ZXiSpV69e8vLy0vbt280xXbt2ld1uN8fExsYqOztbP/74Y7nHLCwslMvlclsAAEDNVOkBpnfv3vr73/+ujRs36rnnntOWLVsUFxen8+fPS5Ly8vIUHBzsto2Pj48CAwOVl5dnjgkJCXEbU7peOuZCKSkpCggIMJfw8PDKPjUAAFBNVPgtpMsZPHiw+XPr1q3Vpk0bNWnSRJ988ol69uxZ2YczJSUlafLkyea6y+UixAAAUENV+WPUN954oxo2bKgDBw5IkpxOp44fP+42pri4WCdPnjTnzTidTuXn57uNKV2/2Nwah8Mhf39/twUAANRMVR5gvvvuO504cUKhoaGSpOjoaJ06dUqZmZnmmE2bNqmkpESdOnUyx6Snp+vcuXPmmLS0NDVr1kwNGjSo6pIBAEA1V+EAc/r0aWVlZSkrK0uSlJOTo6ysLOXm5ur06dOaMmWKPvvsMx06dEgbN27U73//ezVt2lSxsbGSpFtuuUW9e/fWmDFj9Pnnn+vTTz/V+PHjNXjwYIWFhUmS7r//ftntdo0ePVp79+7VypUr9eKLL7q9RQQAAK5dFQ4wO3bsUPv27dW+fXtJ0uTJk9W+fXtNmzZN3t7e2rVrl/r166ebb75Zo0ePVlRUlLZu3SqHw2HuY9myZWrevLl69uypPn36qHPnzm6f8RIQEKD169crJydHUVFR+tOf/qRp06bxCDUAAJB0BZN4u3fvLsMwLtr/8ccfX3YfgYGBWr58+SXHtGnTRlu3bq1oeQAA4BrAdyEBAADLIcAAAADLqfTPgQFw9TR+fG2l7OfQrPhK2Q8AXC3cgQEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZT4QCTnp6uvn37KiwsTDabTatXrzb7zp07p8TERLVu3Vp169ZVWFiYhg8frqNHj7rto3HjxrLZbG7LrFmz3Mbs2rVLXbp0Ue3atRUeHq7U1NQrO0MAAFDjVDjAnDlzRm3bttX8+fPL9J09e1Y7d+7U1KlTtXPnTq1atUrZ2dnq169fmbEzZ87UsWPHzOXRRx81+1wul2JiYhQREaHMzEzNnj1bycnJWrRoUUXLBQAANZBPRTeIi4tTXFxcuX0BAQFKS0tza3v55Zd12223KTc3V40aNTLb/fz85HQ6y93PsmXLVFRUpMWLF8tut6tly5bKysrSnDlzNHbs2IqWDAAAapgqnwNTUFAgm82m+vXru7XPmjVLQUFBat++vWbPnq3i4mKzLyMjQ127dpXdbjfbYmNjlZ2drR9//LHc4xQWFsrlcrktAACgZqrwHZiK+OWXX5SYmKghQ4bI39/fbJ8wYYJuvfVWBQYGatu2bUpKStKxY8c0Z84cSVJeXp4iIyPd9hUSEmL2NWjQoMyxUlJSNGPGjCo8GwAAUF1UWYA5d+6cBg0aJMMwtGDBAre+yZMnmz+3adNGdrtd48aNU0pKihwOxxUdLykpyW2/LpdL4eHhV1Y8AACo1qokwJSGl8OHD2vTpk1ud1/K06lTJxUXF+vQoUNq1qyZnE6n8vPz3caUrl9s3ozD4bji8AMAAKyl0ufAlIaX/fv3a8OGDQoKCrrsNllZWfLy8lJwcLAkKTo6Wunp6Tp37pw5Ji0tTc2aNSv37SMAAHBtqfAdmNOnT+vAgQPmek5OjrKyshQYGKjQ0FDde++92rlzp9asWaPz588rLy9PkhQYGCi73a6MjAxt375dPXr0kJ+fnzIyMjRp0iQ98MADZji5//77NWPGDI0ePVqJiYnas2ePXnzxRb3wwguVdNoAAMDKKhxgduzYoR49epjrpfNORowYoeTkZL3//vuSpHbt2rltt3nzZnXv3l0Oh0MrVqxQcnKyCgsLFRkZqUmTJrnNXwkICND69euVkJCgqKgoNWzYUNOmTeMRagAAIOkKAkz37t1lGMZF+y/VJ0m33nqrPvvss8sep02bNtq6dWtFywMAANcAvgsJAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYToUDTHp6uvr27auwsDDZbDatXr3ard8wDE2bNk2hoaGqU6eOevXqpf3797uNOXnypIYOHSp/f3/Vr19fo0eP1unTp93G7Nq1S126dFHt2rUVHh6u1NTUip8dAACokSocYM6cOaO2bdtq/vz55fanpqbqpZde0sKFC7V9+3bVrVtXsbGx+uWXX8wxQ4cO1d69e5WWlqY1a9YoPT1dY8eONftdLpdiYmIUERGhzMxMzZ49W8nJyVq0aNEVnCIAAKhpfCq6QVxcnOLi4srtMwxDc+fO1ZNPPqnf//73kqS///3vCgkJ0erVqzV48GB9/fXXWrdunb744gt16NBBkjRv3jz16dNHzz//vMLCwrRs2TIVFRVp8eLFstvtatmypbKysjRnzhy3oPNrhYWFKiwsNNddLldFTw0AAFhEpc6BycnJUV5ennr16mW2BQQEqFOnTsrIyJAkZWRkqH79+mZ4kaRevXrJy8tL27dvN8d07dpVdrvdHBMbG6vs7Gz9+OOP5R47JSVFAQEB5hIeHl6ZpwYAAKqRSg0weXl5kqSQkBC39pCQELMvLy9PwcHBbv0+Pj4KDAx0G1PePn59jAslJSWpoKDAXI4cOfLfnxAAAKiWKvwWUnXlcDjkcDg8XQYAALgKKvUOjNPplCTl5+e7tefn55t9TqdTx48fd+svLi7WyZMn3caUt49fHwMAAFy7KjXAREZGyul0auPGjWaby+XS9u3bFR0dLUmKjo7WqVOnlJmZaY7ZtGmTSkpK1KlTJ3NMenq6zp07Z45JS0tTs2bN1KBBg8osGQAAWFCFA8zp06eVlZWlrKwsSf+ZuJuVlaXc3FzZbDZNnDhRTz/9tN5//33t3r1bw4cPV1hYmPr37y9JuuWWW9S7d2+NGTNGn3/+uT799FONHz9egwcPVlhYmCTp/vvvl91u1+jRo7V3716tXLlSL774oiZPnlxpJw4AAKyrwnNgduzYoR49epjrpaFixIgRWrp0qf785z/rzJkzGjt2rE6dOqXOnTtr3bp1ql27trnNsmXLNH78ePXs2VNeXl4aOHCgXnrpJbM/ICBA69evV0JCgqKiotSwYUNNmzbtoo9QAwCAa0uFA0z37t1lGMZF+202m2bOnKmZM2dedExgYKCWL19+yeO0adNGW7durWh5AADgGsB3IQEAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMupMV8lgMrR+PG1lbKfQ7PiK2U/AACUhzswAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcvg2agCVhm8zB3C1cAcGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYTqUHmMaNG8tms5VZEhISJEndu3cv0/fwww+77SM3N1fx8fHy9fVVcHCwpkyZouLi4souFQAAWFSlfxv1F198ofPnz5vre/bs0d13360//OEPZtuYMWM0c+ZMc93X19f8+fz584qPj5fT6dS2bdt07NgxDR8+XLVq1dKzzz5b2eUCAAALqvQAc91117mtz5o1S02aNFG3bt3MNl9fXzmdznK3X79+vfbt26cNGzYoJCRE7dq101NPPaXExEQlJyfLbreXu11hYaEKCwvNdZfLVQlnAwAAqqMqnQNTVFSkt956Sw8++KBsNpvZvmzZMjVs2FCtWrVSUlKSzp49a/ZlZGSodevWCgkJMdtiY2Plcrm0d+/eix4rJSVFAQEB5hIeHl41JwUAADyu0u/A/Nrq1at16tQpjRw50my7//77FRERobCwMO3atUuJiYnKzs7WqlWrJEl5eXlu4UWSuZ6Xl3fRYyUlJWny5MnmusvlIsQAAFBDVWmAef311xUXF6ewsDCzbezYsebPrVu3VmhoqHr27KmDBw+qSZMmV3wsh8Mhh8PxX9ULAACsocreQjp8+LA2bNighx566JLjOnXqJEk6cOCAJMnpdCo/P99tTOn6xebNAACAa0uVBZglS5YoODhY8fHxlxyXlZUlSQoNDZUkRUdHa/fu3Tp+/Lg5Ji0tTf7+/mrRokVVlQsAACykSt5CKikp0ZIlSzRixAj5+PzfIQ4ePKjly5erT58+CgoK0q5duzRp0iR17dpVbdq0kSTFxMSoRYsWGjZsmFJTU5WXl6cnn3xSCQkJvEUEAAAkVVGA2bBhg3Jzc/Xggw+6tdvtdm3YsEFz587VmTNnFB4eroEDB+rJJ580x3h7e2vNmjV65JFHFB0drbp162rEiBFunxsDAACubVUSYGJiYmQYRpn28PBwbdmy5bLbR0RE6MMPP6yK0gAAQA3AdyEBAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLqfQAk5ycLJvN5rY0b97c7P/ll1+UkJCgoKAg1atXTwMHDlR+fr7bPnJzcxUfHy9fX18FBwdrypQpKi4uruxSAQCARflUxU5btmypDRs2/N9BfP7vMJMmTdLatWv1zjvvKCAgQOPHj9eAAQP06aefSpLOnz+v+Ph4OZ1Obdu2TceOHdPw4cNVq1YtPfvss1VRLgAAsJgqCTA+Pj5yOp1l2gsKCvT6669r+fLluuuuuyRJS5Ys0S233KLPPvtMt99+u9avX699+/Zpw4YNCgkJUbt27fTUU08pMTFRycnJstvt5R6zsLBQhYWF5rrL5aqKUwMAANVAlcyB2b9/v8LCwnTjjTdq6NChys3NlSRlZmbq3Llz6tWrlzm2efPmatSokTIyMiRJGRkZat26tUJCQswxsbGxcrlc2rt370WPmZKSooCAAHMJDw+vilMDAADVQKUHmE6dOmnp0qVat26dFixYoJycHHXp0kU//fST8vLyZLfbVb9+fbdtQkJClJeXJ0nKy8tzCy+l/aV9F5OUlKSCggJzOXLkSOWeGAAAqDYq/S2kuLg48+c2bdqoU6dOioiI0Ntvv606depU9uFMDodDDoejyvYPAACqjyp/jLp+/fq6+eabdeDAATmdThUVFenUqVNuY/Lz8805M06ns8xTSaXr5c2rAQAA154qDzCnT5/WwYMHFRoaqqioKNWqVUsbN240+7Ozs5Wbm6vo6GhJUnR0tHbv3q3jx4+bY9LS0uTv768WLVpUdbkAAMACKv0tpP/5n/9R3759FRERoaNHj2r69Ony9vbWkCFDFBAQoNGjR2vy5MkKDAyUv7+/Hn30UUVHR+v222+XJMXExKhFixYaNmyYUlNTlZeXpyeffFIJCQm8RQQAACRVQYD57rvvNGTIEJ04cULXXXedOnfurM8++0zXXXedJOmFF16Ql5eXBg4cqMLCQsXGxuqVV14xt/f29taaNWv0yCOPKDo6WnXr1tWIESM0c+bMyi4VAABYVKUHmBUrVlyyv3bt2po/f77mz59/0TERERH68MMPK7s0AABQQ/BdSAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHJ8PF0AAFSVxo+vrZT9HJoVXyn7AVB5uAMDAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAsp9IDTEpKijp27Cg/Pz8FBwerf//+ys7OdhvTvXt32Ww2t+Xhhx92G5Obm6v4+Hj5+voqODhYU6ZMUXFxcWWXCwAALKjSv416y5YtSkhIUMeOHVVcXKy//OUviomJ0b59+1S3bl1z3JgxYzRz5kxz3dfX1/z5/Pnzio+Pl9Pp1LZt23Ts2DENHz5ctWrV0rPPPlvZJXsM35QLAMCVqfQAs27dOrf1pUuXKjg4WJmZmeratavZ7uvrK6fTWe4+1q9fr3379mnDhg0KCQlRu3bt9NRTTykxMVHJycmy2+2VXTYAALCQKp8DU1BQIEkKDAx0a1+2bJkaNmyoVq1aKSkpSWfPnjX7MjIy1Lp1a4WEhJhtsbGxcrlc2rt3b7nHKSwslMvlclsAAEDNVOl3YH6tpKREEydO1J133qlWrVqZ7ffff78iIiIUFhamXbt2KTExUdnZ2Vq1apUkKS8vzy28SDLX8/Lyyj1WSkqKZsyYUUVnAgAAqpMqDTAJCQnas2eP/vWvf7m1jx071vy5devWCg0NVc+ePXXw4EE1adLkio6VlJSkyZMnm+sul0vh4eFXVjgAAKjWquwtpPHjx2vNmjXavHmzbrjhhkuO7dSpkyTpwIEDkiSn06n8/Hy3MaXrF5s343A45O/v77YAAICaqdIDjGEYGj9+vN59911t2rRJkZGRl90mKytLkhQaGipJio6O1u7du3X8+HFzTFpamvz9/dWiRYvKLhkAAFhMpb+FlJCQoOXLl+u9996Tn5+fOWclICBAderU0cGDB7V8+XL16dNHQUFB2rVrlyZNmqSuXbuqTZs2kqSYmBi1aNFCw4YNU2pqqvLy8vTkk08qISFBDoejsksGAAAWU+l3YBYsWKCCggJ1795doaGh5rJy5UpJkt1u14YNGxQTE6PmzZvrT3/6kwYOHKgPPvjA3Ie3t7fWrFkjb29vRUdH64EHHtDw4cPdPjcGAABcuyr9DoxhGJfsDw8P15YtWy67n4iICH344YeVVRYAAKhB+C4kAABgOQQYAABgOQQYAABgOQQYAABgOQQYAABgOQQYAABgOQQYAABgOQQYAABgOQQYAABgOQQYAABgOQQYAABgOQQYAABgOQQYAABgOQQYAABgOQQYAABgOQQYAABgOT6eLgAArhWNH19bKfs5NCu+UvYDWBl3YAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOUQYAAAgOX4eLqAS5k/f75mz56tvLw8tW3bVvPmzdNtt93m6bIAoEZo/PjaStnPoVnxlbIfoCKqbYBZuXKlJk+erIULF6pTp06aO3euYmNjlZ2dreDgYI/WVll/6AEAwJWptm8hzZkzR2PGjNGoUaPUokULLVy4UL6+vlq8eLGnSwMAAB5WLe/AFBUVKTMzU0lJSWabl5eXevXqpYyMjHK3KSwsVGFhobleUFAgSXK5XJVeX0nh2Urf53+jMs+xss6tsmqinkujnkujnkurbvW0mv5xpexnz4zYStkPPKP09WQYxqUHGtXQ999/b0gytm3b5tY+ZcoU47bbbit3m+nTpxuSWFhYWFhYWGrAcuTIkUtmhWp5B+ZKJCUlafLkyeZ6SUmJTp48qaCgINlsNg9WVnVcLpfCw8N15MgR+fv7e7qcaoFrUj6uS1lck/JxXcrimpRVldfEMAz99NNPCgsLu+S4ahlgGjZsKG9vb+Xn57u15+fny+l0lruNw+GQw+Fwa6tfv35VlVit+Pv784fqAlyT8nFdyuKalI/rUhbXpKyquiYBAQGXHVMtJ/Ha7XZFRUVp48aNZltJSYk2btyo6OhoD1YGAACqg2p5B0aSJk+erBEjRqhDhw667bbbNHfuXJ05c0ajRo3ydGkAAMDDqm2Aue+++/TDDz9o2rRpysvLU7t27bRu3TqFhIR4urRqw+FwaPr06WXeOruWcU3Kx3Upi2tSPq5LWVyTsqrDNbEZxuWeUwIAAKhequUcGAAAgEshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwFjcrFmzZLPZNHHiRE+X4nHff/+9HnjgAQUFBalOnTpq3bq1duzY4emyPOb8+fOaOnWqIiMjVadOHTVp0kRPPfXU5b8grYZJT09X3759FRYWJpvNptWrV7v1G4ahadOmKTQ0VHXq1FGvXr20f/9+zxR7lVzqmpw7d06JiYlq3bq16tatq7CwMA0fPlxHjx71XMFXyeVeK7/28MMPy2azae7cuVetPk/4Ldfk66+/Vr9+/RQQEKC6deuqY8eOys3NrfLaCDAW9sUXX+jVV19VmzZtPF2Kx/3444+68847VatWLX300Ufat2+f/vrXv6pBgwaeLs1jnnvuOS1YsEAvv/yyvv76az333HNKTU3VvHnzPF3aVXXmzBm1bdtW8+fPL7c/NTVVL730khYuXKjt27erbt26io2N1S+//HKVK716LnVNzp49q507d2rq1KnauXOnVq1apezsbPXr188DlV5dl3utlHr33Xf12WefXfa7emqCy12TgwcPqnPnzmrevLk++eQT7dq1S1OnTlXt2rWrvrjK+PZoXH0//fSTcdNNNxlpaWlGt27djMcee8zTJXlUYmKi0blzZ0+XUa3Ex8cbDz74oFvbgAEDjKFDh3qoIs+TZLz77rvmeklJieF0Oo3Zs2ebbadOnTIcDofxj3/8wwMVXn0XXpPyfP7554Yk4/Dhw1enqGrgYtflu+++M66//npjz549RkREhPHCCy9c9do8pbxrct999xkPPPCAR+rhDoxFJSQkKD4+Xr169fJ0KdXC+++/rw4dOugPf/iDgoOD1b59e7322mueLsuj7rjjDm3cuFHffPONJOmrr77Sv/71L8XFxXm4suojJydHeXl5bn+OAgIC1KlTJ2VkZHiwsuqloKBANpvtmvmC3IspKSnRsGHDNGXKFLVs2dLT5XhcSUmJ1q5dq5tvvlmxsbEKDg5Wp06dLvnWW2UiwFjQihUrtHPnTqWkpHi6lGrj22+/1YIFC3TTTTfp448/1iOPPKIJEybojTfe8HRpHvP4449r8ODBat68uWrVqqX27dtr4sSJGjp0qKdLqzby8vIkqcxXlISEhJh917pffvlFiYmJGjJkyDX/TczPPfecfHx8NGHCBE+XUi0cP35cp0+f1qxZs9S7d2+tX79e99xzjwYMGKAtW7ZU+fGr7XchoXxHjhzRY489prS0tKvzHqNFlJSUqEOHDnr22WclSe3bt9eePXu0cOFCjRgxwsPVecbbb7+tZcuWafny5WrZsqWysrI0ceJEhYWFXbPXBBVz7tw5DRo0SIZhaMGCBZ4ux6MyMzP14osvaufOnbLZbJ4up1ooKSmRJP3+97/XpEmTJEnt2rXTtm3btHDhQnXr1q1Kj88dGIvJzMzU8ePHdeutt8rHx0c+Pj7asmWLXnrpJfn4+Oj8+fOeLtEjQkND1aJFC7e2W2655arMhK+upkyZYt6Fad26tYYNG6ZJkyZx5+5XnE6nJCk/P9+tPT8/3+y7VpWGl8OHDystLe2av/uydetWHT9+XI0aNTL/7j18+LD+9Kc/qXHjxp4uzyMaNmwoHx8fj/3dyx0Yi+nZs6d2797t1jZq1Cg1b95ciYmJ8vb29lBlnnXnnXcqOzvbre2bb75RRESEhyryvLNnz8rLy/13FG9vb/O3JkiRkZFyOp3auHGj2rVrJ0lyuVzavn27HnnkEc8W50Gl4WX//v3avHmzgoKCPF2Sxw0bNqzMnMPY2FgNGzZMo0aN8lBVnmW329WxY0eP/d1LgLEYPz8/tWrVyq2tbt26CgoKKtN+LZk0aZLuuOMOPfvssxo0aJA+//xzLVq0SIsWLfJ0aR7Tt29fPfPMM2rUqJFatmypL7/8UnPmzNGDDz7o6dKuqtOnT+vAgQPmek5OjrKyshQYGKhGjRpp4sSJevrpp3XTTTcpMjJSU6dOVVhYmPr37++5oqvYpa5JaGio7r33Xu3cuVNr1qzR+fPnzflAgYGBstvtniq7yl3utXJhkKtVq5acTqeaNWt2tUu9ai53TaZMmaL77rtPXbt2VY8ePbRu3Tp98MEH+uSTT6q+OI88+4RKxWPU//HBBx8YrVq1MhwOh9G8eXNj0aJFni7Jo1wul/HYY48ZjRo1MmrXrm3ceOONxhNPPGEUFhZ6urSravPmzYakMsuIESMMw/jPo9RTp041QkJCDIfDYfTs2dPIzs72bNFV7FLXJCcnp9w+ScbmzZs9XXqVutxr5ULXwmPUv+WavP7660bTpk2N2rVrG23btjVWr159VWqzGcY19rGcAADA8pjECwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALOf/A6WAgQ0ba9GyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)),bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QZXheAdgOVB"
   },
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oref75H9gOVB"
   },
   "outputs": [],
   "source": [
    "tokens = # <list of all unique characters in the dataset>\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "print ('num_tokens = ', num_tokens)\n",
    "\n",
    "assert 50 < num_tokens < 60, \"Names should contain within 50 and 60 unique tokens depending on encoding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzGM7EI-gOVC"
   },
   "source": [
    "### Convert characters to integers\n",
    "\n",
    "PyTorch умеет работать только с числами, а не со строками.\n",
    "Поэтому чтобы натренировать нейросеть, необходимо сопоставить каждому токену уникальное число.\n",
    "\n",
    "Давайте займемся созданием этого маппинга вида \"токен: число\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4zxOfcSgOVC"
   },
   "outputs": [],
   "source": [
    "token_to_id = #<dictionary of symbol -> its identifier (index in tokens list)>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3re-60dMgOVC"
   },
   "outputs": [],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "\n",
    "for i in range(num_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53llt8kjgOVD"
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[' '], dtype='int32', batch_first = True):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        line_ix = [token_to_id[c] for c in names[i]]\n",
    "        names_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        names_ix = np.transpose(names_ix)\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVI1sSuMgOVD"
   },
   "outputs": [],
   "source": [
    "names[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udi9zqJzgOVE"
   },
   "outputs": [],
   "source": [
    "#Example: cast 4 random names to matrices, pad with zeros\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foZFrgv-gOVE"
   },
   "source": [
    "# Recurrent neural network\n",
    "\n",
    "Мы можем переписать архитектуру нейронной сети в следующем виде: входной тензор размерности $x_t$ и тензор предыдщего состояния размера $h_t$.\n",
    "<img src=\"https://github.com/neychev/made_nlp_course/blob/spring2021/week00_RNNs_and_Language_Models/rnn.png?raw=1\" width=480>\n",
    "\n",
    "Для тренировки языковой модели необходимо дополнить архитектуру двумя вещами:\n",
    "* Добавить слой эмбеддинга, который конвертирует x_t в вектор нужной размерности.\n",
    "* Выходной слой, предсказывающий вероятности следующего токена в последовательности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lP8ShX5PgOVE"
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDyQ_9NygOVE"
   },
   "outputs": [],
   "source": [
    "class CharRNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement the scheme above as torch module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
    "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "        # get vector embedding of x\n",
    "        x_emb = self.embedding(x)\n",
    "        \n",
    "        # compute next hidden state using self.rnn_update\n",
    "        # hint: use torch.cat(..., dim=...) for concatenation\n",
    "        x_and_h = # YOUR CODE HERE\n",
    "        h_next = # YOUR CODE HERE\n",
    "        \n",
    "        h_next = # YOUR CODE HERE\n",
    "        \n",
    "        assert h_next.size() == h_prev.size()\n",
    "        \n",
    "        #compute logits for next character probs\n",
    "        logits = # YOUR CODE\n",
    "        \n",
    "        return h_next, F.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
    "        return torch.zeros(batch_size, self.num_units, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPYuMtZwgOVF"
   },
   "outputs": [],
   "source": [
    "char_rnn = CharRNNCell()\n",
    "criterion = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tCvCqIWgOVF"
   },
   "source": [
    "### RNN loop\n",
    "\n",
    "Как только мы определили один шаг RNN, мы можем применить его в цикле, чтобы получить прогнозы для каждого шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gg1T0wT4gOVF"
   },
   "outputs": [],
   "source": [
    "def rnn_loop(char_rnn, batch_ix):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in names_ix\n",
    "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
    "    \"\"\"\n",
    "    batch_size, max_length = batch_ix.size()\n",
    "    hid_state = char_rnn.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    for x_t in batch_ix.transpose(0,1):\n",
    "        hid_state, logp_next = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
    "        logprobs.append(logp_next)\n",
    "        \n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sNsSc_ggOVF"
   },
   "outputs": [],
   "source": [
    "batch_ix = to_matrix(names[:5])\n",
    "batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "\n",
    "logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "\n",
    "assert torch.max(logp_seq).data.numpy() <= 0\n",
    "assert tuple(logp_seq.size()) ==  batch_ix.shape + (num_tokens,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vgTWr0KgOVF"
   },
   "source": [
    "### Likelihood and gradients\n",
    "\n",
    "Теперь мы можем обучить нашу нейронную сеть минимизировать кроссэнтропию (максимизировать логарифмическое правдоподобие) с фактическими следующими токенами.\n",
    "\n",
    "Чтобы сделать это векторизованным способом, мы берем `batch_ix[:, 1:]` - матрицу идентификаторов токенов, сдвинутую на i шаг влево, так что i-й элемент фактически является «следующим токеном» для i-го прогноза."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JiQWsUmkgOVG"
   },
   "outputs": [],
   "source": [
    "predictions_logp = logp_seq[:, :-1]\n",
    "actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "# .contiguous() method checks that tensor is stored in the memory correctly to \n",
    "# get its view of desired shape.\n",
    "\n",
    "loss = criterion(predictions_logp.contiguous().view(-1, num_tokens), \n",
    "                  actual_next_tokens.contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZswZgAPgOVG"
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SK0ImW_gOVG"
   },
   "outputs": [],
   "source": [
    "for w in char_rnn.parameters():\n",
    "    assert w.grad is not None and torch.max(torch.abs(w.grad)).data.numpy() != 0, \\\n",
    "        \"Loss is not differentiable w.r.t. a weight with shape %s. Check forward method.\" % (w.size(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Q6z7GKjgOVG"
   },
   "source": [
    "### The training loop\n",
    "\n",
    "Мы обучаем наш char-rnn точно так же, как мы обучаем любую модель глубокого обучения: с помощью мини-батч SGD.\n",
    "\n",
    "Единственная разница в том, что на этот раз мы сэмплируем строки, а не изображения или звук."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Run5ZGEKgOVG"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "char_rnn = CharRNNCell()\n",
    "criterion = nn.NLLLoss()\n",
    "opt = torch.optim.Adam(char_rnn.parameters())\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCh-mHdVgOVG"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 16\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(sample(names, 32), max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    \n",
    "    logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "    \n",
    "    # compute loss\n",
    "    predictions_logp = # YOUR CODE HERE\n",
    "    actual_next_tokens = # YOUR CODE HERE\n",
    "\n",
    "    loss = # YOUR CODE HERE\n",
    "    \n",
    "    # train with backprop\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    history.append(loss.data.numpy())\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSbQppj-gOVG"
   },
   "source": [
    "### RNN: sampling\n",
    "После того, как мы немного обучили нашу сеть, давайте приступим к генерированию материала.  \n",
    "Все, что нам нужно, это функция одного шага rnn, которую вы определили в `char_rnn.forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2oAA4MVmgOVH"
   },
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        hid_state, logp_next = char_rnn(x_sequence[:, -1], hid_state)\n",
    "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0]\n",
    "        \n",
    "        # sample next token and push it back into x_sequence\n",
    "        next_ix = np.random.choice(num_tokens,p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3S4Xu9NgOVH"
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(char_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Gam9iWigOVH"
   },
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    print(generate_sample(char_rnn, seed_phrase=' Deb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "I7PaYx8NgOVH"
   },
   "source": [
    "### More seriously\n",
    "\n",
    "То, что мы только что сделали, — это ручная низкоуровневая реализация RNN. Хотя это круто, я думаю, вам не понравится идея каждый раз переписывать его с нуля.\n",
    "\n",
    "Как вы могли догадаться, у torch есть решение для этого. Чтобы быть более конкретным, есть два варианта:\n",
    "* `nn.RNNCell(emb_size, rnn_num_units)` - реализует один шаг RNN, как и вы. В основном concat-linear-tanh\n",
    "* `nn.RNN(emb_size, rnn_num_units` - реализует за вас весь rnn_loop.\n",
    "\n",
    "Есть также «nn.LSTMCell» против «nn.LSTM», «nn.GRUCell» против «nn.GRU» и т. д. и т. д.\n",
    "\n",
    "В этом примере мы перепишем char_rnn и rnn_loop, используя высокоуровневый API rnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEliHxRigOVI"
   },
   "outputs": [],
   "source": [
    "class CharRNNLoop(nn.Module):\n",
    "    def __init__(self, num_tokens=num_tokens, emb_size=16, rnn_num_units=64):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
    "        self.rnn = nn.LSTM(emb_size, rnn_num_units, batch_first=True)\n",
    "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert isinstance(x.data, torch.LongTensor)\n",
    "        h_seq, _ = self.rnn(self.emb(x))\n",
    "        next_logits = self.hid_to_logits(h_seq)\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "        return next_logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MiLsa9QrgOVI"
   },
   "outputs": [],
   "source": [
    "model = CharRNNLoop()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "history = []\n",
    "\n",
    "# the model applies over the whole sequence\n",
    "batch_ix = to_matrix(sample(names, 32), max_len=MAX_LENGTH)\n",
    "batch_ix = torch.LongTensor(batch_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AccwqdLOgOVI"
   },
   "outputs": [],
   "source": [
    "logp_seq = model(batch_ix)\n",
    "\n",
    "loss = criterion(logp_seq[:, :-1].contiguous().view(-1, num_tokens),\n",
    "                 batch_ix[:, 1:].contiguous().view(-1))\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBjyjJodgOVI"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 16\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(sample(names, 32), max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    \n",
    "    logp_seq = model(batch_ix)\n",
    "    \n",
    "    # compute loss\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # train with backprop\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    history.append(loss.data.numpy())\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f3cPsjngOVI"
   },
   "source": [
    "### To sum up:\n",
    "- PyTorch удобен как для прототипирования, так и для производства\n",
    "- Много предустановленных методов/слоев/активаций из коробки\n",
    "- Гораздо проще (*действительно проще*) использовать PyTorch, чем TensorFlow на начальном уровне.\n",
    "- Нейронные сети - это не *черные ящики*, они довольно приятны и просты в использовании (почти всегда)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoQJxh5ngOVJ"
   },
   "source": [
    "### Try it out!\n",
    "Вы только что реализовали рекуррентную языковую модель, перед которой можно генерировать любую последовательность, так что есть много данных, на которых вы можете ее опробовать:\n",
    "\n",
    "* Романы/стихи/песни вашего любимого автора\n",
    "* Заголовки новостей/заголовки кликбейтов\n",
    "* Исходный код Linux или Tensorflow\n",
    "* Мелодия в формате нот/аккордов\n",
    "* Названия каталога ИКЕА\n",
    "* Имена покемонов\n",
    "* Карты из Magic, the Gathering/Hearthstone\n",
    "\n",
    "Если вы хотите попробовать, вот что вы хотите посмотреть:\n",
    "* Текущий формат данных представляет собой последовательность строк, поэтому роман можно отформатировать как список предложений. Кроме того, вы можете полностью изменить предварительную обработку данных.\n",
    "* Хотя некоторые наборы данных уже доступны и собраны, другие можно получить только из Интернета. Попробуйте для этого Selenium или Scrapy.\n",
    "* Убедитесь, что MAX_LENGTH настроен для более длинных наборов данных.\n",
    "* Более сложные задачи требуют большей архитектуры RNN, попробуйте больше нейронов или несколько слоев. Это также потребует большего количества итераций обучения.\n",
    "* Долгосрочные зависимости в музыке, романах или молекулах лучше обрабатываются с помощью LSTM или GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nn_fall_2022_venv",
   "language": "python",
   "name": "nn_fall_2022_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
