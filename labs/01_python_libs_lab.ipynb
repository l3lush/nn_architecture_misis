{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hTOjrLHi4g_"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import _pickle as cPickle\n",
    "import gzip\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2Gqyx4qi4hA"
   },
   "source": [
    "# Task 1. Fill `one_hot_encoded`, `check_accuracy` and `softmax` functions\n",
    "\n",
    "## 1.1 `One Hot Encoding`\n",
    "![OHE](https://media.geeksforgeeks.org/wp-content/uploads/20200716042622/vector.png)\n",
    "\n",
    "## 1.2 `Accuracy` function\n",
    "Shows share of correct predictions. \n",
    "\n",
    "\n",
    "## 1.3 `Softmax` function (see formula)\n",
    "  \n",
    "![Softmax](https://raw.githubusercontent.com/l3lush/nn_architecture_misis/fall2022/images/softmax.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErBETnrQi4hB"
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "def one_hot_encoded(y, num_class):\n",
    "    # TODO\n",
    "    # num_class - number of classes (integer type, e.g. 5)\n",
    "    # return only one hot encoded output vector\n",
    "    # Realize me\n",
    "    pass\n",
    "\n",
    "\n",
    "def check_accuracy(y_true, y_pred):\n",
    "    # TODO\n",
    "    # hint: both (y_true and y_pred) are NOT one hot encoded\n",
    "    # Realize me\n",
    "    pass \n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    # TODO\n",
    "    # Realize me\n",
    "    pass \n",
    "    \n",
    "\n",
    "# l2 regularization\n",
    "def l2_reg(layers, lam=0.001):\n",
    "    reg_loss = 0.0\n",
    "    for layer in layers:\n",
    "        if hasattr(layer, 'W'):\n",
    "            reg_loss += 0.5 * lam * np.sum(layer.W * layer.W)\n",
    "    return reg_loss\n",
    "\n",
    "\n",
    "# l2 regularization grad\n",
    "def delta_l2_reg(layers, grads, lam=0.001):\n",
    "    for layer, grad in zip(layers, reversed(grads)):\n",
    "        if hasattr(layer, 'W'):\n",
    "            grad[0] += lam * layer.W\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ik4HMyFlm8MQ"
   },
   "outputs": [],
   "source": [
    "example = np.array([0, 1, 2, 1, 3])\n",
    "answer = np.array([[1, 0, 0, 0],\n",
    "                   [0, 1, 0, 0],\n",
    "                   [0, 0, 1, 0],\n",
    "                   [0, 1, 0, 0],\n",
    "                   [0, 0, 0, 1]])\n",
    "assert np.array_equal(one_hot_encoded(example, 4), answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELx4GdzZi4hC"
   },
   "outputs": [],
   "source": [
    "example = np.array([[1.3, 5.1, 2.2, 0.7, 1.1]])\n",
    "answer = np.array([[0.02, 0.9 , 0.05, 0.01, 0.02]])\n",
    "assert np.isclose(softmax(example), answer, atol=1e-2).min()\n",
    "\n",
    "example = np.array([[1.3, 5.1, 2.2, 0.7, 1.1],\n",
    "                    [1.5, 4.1, 5.3, 0.1, 2.5]])\n",
    "answer = np.array([[0.02, 0.9 , 0.05, 0.01, 0.02],\n",
    "                   [0.02, 0.22, 0.72, 0.00, 0.04]])\n",
    "assert np.isclose(softmax(example), answer, atol=1e-2).min()\n",
    "\n",
    "np.random.seed(17)\n",
    "example = np.random.random(size=(4, 5))\n",
    "answer = np.array([[0.17853034, 0.22603284, 0.16103381, 0.14230803, 0.29209498],\n",
    "                   [0.23894089, 0.2344878 , 0.22040914, 0.12888823, 0.17727395],\n",
    "                   [0.27197834, 0.11217767, 0.25065597, 0.25399886, 0.11118916],\n",
    "                   [0.2279702 , 0.20613838, 0.21579083, 0.19254404, 0.15755655]])\n",
    "assert np.isclose(softmax(example), answer, atol=1e-2).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "aZDKA4Szi4hC",
    "outputId": "f4f0affc-e22a-423c-e16a-f914443d9b22"
   },
   "outputs": [],
   "source": [
    "y_true_example = np.array([1, 0, 0, 1, 0])\n",
    "y_pred_example = np.array([1, 1, 1, 0, 1])\n",
    "assert check_accuracy(y_true_example, y_pred_example) == 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6IdYogni4hC"
   },
   "outputs": [],
   "source": [
    "def eval_numerical_gradient(f, x, verbose=False, h=0.00001):\n",
    "    \"\"\"Evaluates gradient df/dx via finite differences:\n",
    "    df/dx ~ (f(x+h) - f(x-h)) / 2h\n",
    "    Adopted from https://github.com/ddtm/dl-course/\n",
    "    \"\"\"\n",
    "    fx = f(x) # evaluate function value at original point\n",
    "    grad = np.zeros_like(x)\n",
    "    # iterate over all indexes in x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "\n",
    "        # evaluate function at x+h\n",
    "        ix = it.multi_index\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h # increment by h\n",
    "        fxph = f(x) # evalute f(x + h)\n",
    "        x[ix] = oldval - h\n",
    "        fxmh = f(x) # evaluate f(x - h)\n",
    "        x[ix] = oldval # restore\n",
    "\n",
    "        # compute the partial derivative with centered formula\n",
    "        grad[ix] = (fxph - fxmh) / (2 * h) # the slope\n",
    "        if verbose:\n",
    "            print (ix, grad[ix])\n",
    "        it.iternext() # step to next dimension\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0vez1Rti4hD"
   },
   "source": [
    "# Task 2. Realize `ReLU` Class\n",
    "\n",
    "You need to realize these function:  \n",
    "  \n",
    "![ReLU Image](https://pytorch.org/docs/stable/_images/ReLU.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHIbVQQHi4hD"
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.gradInput = None\n",
    "        self.X = None\n",
    "\n",
    "    def forward(self, X, mode):\n",
    "        # TODO: realize forward pass of ReLU layer\n",
    "        # also save X value to self.X\n",
    "        # YOUR CODE HERE\n",
    "        return X\n",
    "    \n",
    "    def backward(self, dout, mode):\n",
    "        # TODO: realize backward pass of ReLU layer\n",
    "        # dout - gradient from forward layer,\n",
    "        self.gradInput = dout.copy()\n",
    "\n",
    "        # convert to correct values\n",
    "        self.gradInput = None # YOUR CODE HERE\n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "oOGCh6-bi4hD",
    "outputId": "2601cb4f-af48-450a-827b-3d7a56222474"
   },
   "outputs": [],
   "source": [
    "points = np.linspace(-1, 1, 10*12).reshape([10, 12])\n",
    "relu = ReLU()\n",
    "f = lambda x: relu.forward(x, mode='train').sum(axis=1).sum()\n",
    "res = f(points)\n",
    "numeric_grads = eval_numerical_gradient(f, points)\n",
    "print(numeric_grads)\n",
    "inp_grad = np.ones(shape=(10, 12))\n",
    "grads = relu.backward(inp_grad, mode='train')[0]\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bU6LlXr_qeqP"
   },
   "source": [
    "# Task 3. Realize `Linear` class\n",
    "\n",
    "![Linear Forward](https://miro.medium.com/max/960/1*0lejoYyyQWjYzEP_BNW2nw.jpeg)\n",
    "  \n",
    "Forward pass formula:  \n",
    "$$ output = XW + B $$ \n",
    "In our realization there is **NO** need in transposing $ X $.\n",
    "  \n",
    "Backward pass formulas:  \n",
    "$$ dW = X^{T} \\cdot dZ $$\n",
    "$$ dB = \\frac{dZ}{m}$$\n",
    "$$ d(Input) = dZ \\cdot W^{T}$$\n",
    "where  \n",
    "$dZ$ - grad from forward layer,  \n",
    "$m$ - number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-IPpB29i4hE"
   },
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, in_size, out_size):\n",
    "        # Xavier init\n",
    "        self.W = np.random.randn(in_size, out_size) / np.sqrt(in_size + out_size/ 2.)\n",
    "        self.b = np.zeros((1, out_size))\n",
    "        self.params = [self.W, self.b]\n",
    "        self.gradW = None\n",
    "        self.gradB = None\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X, mode):\n",
    "        # TODO: realize forward pass for Linear Layer\n",
    "        # dont forget to save X in self.X\n",
    "        self.X = X\n",
    "        output = # YOUR CODE HERE\n",
    "        return output\n",
    "    \n",
    "    def backward(self, dout, mode):\n",
    "        self.gradW = # YOUR CODE HERE \n",
    "        self.gradB = # YOUR CODE HERE \n",
    "        self.gradInput = # YOUR CODE HERE \n",
    "        return self.gradInput, [self.gradW, self.gradB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70g8Bvaji4hE",
    "outputId": "6a91fee3-6628-44b1-8a39-bfe9e5bddd3d"
   },
   "outputs": [],
   "source": [
    "points = np.linspace(-1, 1, 10*12).reshape([10, 12])\n",
    "relu = Linear(12, 5)\n",
    "f = lambda x: relu.forward(x, mode='train').sum(axis=1).sum()\n",
    "res = f(points)\n",
    "numeric_grads = eval_numerical_gradient(f, points)\n",
    "print(numeric_grads)\n",
    "inp_grad = np.ones(shape=(10, 5))\n",
    "grads = relu.backward(inp_grad, mode='train')[0]\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3L_EZ3oNyGVv"
   },
   "source": [
    "# Task 4. Realize `CrossEntropyLoss` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_U4-_srQdI_I"
   },
   "source": [
    "Cross Entropy Loss forward pass formula:\n",
    "$$ Loss = \\frac{1}{M} \\sum_{j=0}^{M}{\\sum_{i=0}^{N}{-y_{i}^{j}log(\\hat{y}_{i}^{j}) }} $$\n",
    "$M$ - number of observations in batch (see Task 5)  \n",
    "$N$ - number of classes  \n",
    "$y$ - true label of observation  \n",
    "$\\hat{y}$ - predicted label proba (softmax) of observation \n",
    "  \n",
    "Do backward pass formula for yourself (hint: you finally only need decrease all probas by 1 and devide it by m).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pX07daOii4hF"
   },
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(object):\n",
    "    def forward(self, X, y):\n",
    "        # Hint: save y.shape and softmax probas\n",
    "        # it is need for backward pass\n",
    "        self.m =\n",
    "        self.p =\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        dx = self.p.copy()\n",
    "        # YOUR CODE HERE\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQD9o8_Hb1bv"
   },
   "outputs": [],
   "source": [
    "example = np.array([[1, 2, 3], \n",
    "                    [4, 5, 6]])  # it is raw output of some abstract model, \n",
    "                                 # we got 2 observations\n",
    "                                 # an we got 3 classes \n",
    "y_example = np.array([1, 0])  # true labels of batch. ATTENTION: this is not one hot encoded vector\n",
    "celoss = CrossEntropyLoss()\n",
    "assert round(celoss.forward(example, y_example), 5) == 1.90761"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABTmpn9ki4hF"
   },
   "source": [
    "## NN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBjntjwIi4hF"
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, loss_func=CrossEntropyLoss(), mode = 'train'):\n",
    "        self.layers = []\n",
    "        self.params = []\n",
    "        self.loss_func = loss_func\n",
    "        self.grads = []\n",
    "        self.mode = mode\n",
    "\n",
    "    def add_layer(self,layer):\n",
    "        self.layers.append(layer)\n",
    "        self.params.append(layer.params)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X, self.mode)\n",
    "        return X\n",
    "\n",
    "    def backward(self, dout):\n",
    "        self.clear_grad_param()\n",
    "        for layer in reversed(self.layers):\n",
    "            dout, grad = layer.backward(dout, self.mode)\n",
    "            self.grads.append(grad)\n",
    "        return self.grads\n",
    "\n",
    "    def train_step(self, X, y):\n",
    "        out = self.forward(X)\n",
    "        loss = self.loss_func.forward(out,y)\n",
    "        dout = self.loss_func.backward(out,y)\n",
    "        loss += l2_reg(self.layers)\n",
    "        grads = self.backward(dout)\n",
    "        grads = delta_l2_reg(self.layers, grads)\n",
    "        return loss, grads\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.forward(X)\n",
    "        return np.argmax(softmax(X), axis=1)\n",
    "\n",
    "    def dispGradParam():\n",
    "        print(self.grads)\n",
    "    \n",
    "    def clear_grad_param(self):\n",
    "        self.grads = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b-VmfLKmSFc"
   },
   "source": [
    "# Task 5. Realize `minibatch` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVwl_22hi4hG"
   },
   "outputs": [],
   "source": [
    "# SGD with momentum\n",
    "def update(velocity, params, grads, learning_rate=0.001, mu=0.9):\n",
    "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
    "        for i in range(len(g)):\n",
    "            v[i] = mu * v[i] + learning_rate * g[i]\n",
    "            p[i] -= v[i]\n",
    "\n",
    "\n",
    "# get minibatches\n",
    "def minibatch(X, y, minibatch_size):\n",
    "    \"\"\"\n",
    "    Cut X and y into minibatches and store it in \n",
    "    minibatched list like (X_batch, y_batch)\n",
    "    Example: [(X_batch1, y_batch1), (X_batch2, y_batch2)]\n",
    "\n",
    "    Note:\n",
    "    DO NOT FORGET TO SHUFFLE X AND Y\n",
    "    \"\"\"\n",
    "    minibatches = []\n",
    "    # TODO: Realize me\n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGNajLrci4hG"
   },
   "outputs": [],
   "source": [
    "def plot_train_process(train_acc_list, val_acc_list, \n",
    "                       mean_train_loss_list, mean_val_loss_list):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    axes[0].set_title('Accuracy')\n",
    "    axes[1].set_title('Loss')\n",
    "    \n",
    "    axes[0].plot(train_acc_list, label='train')\n",
    "    axes[0].plot(val_acc_list, label='val')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].plot(mean_train_loss_list, label='train')\n",
    "    axes[1].plot(mean_val_loss_list, label='val')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu=0.9,\n",
    "                 verbose=True, X_val=None, y_val=None, nesterov=True, draw_each_iters=5):\n",
    "    val_loss_epoch = []\n",
    "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
    "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
    "\n",
    "    c = 0 \n",
    "\n",
    "    mean_train_loss_list = []\n",
    "    mean_val_loss_list = []\n",
    "    train_acc_list = []\n",
    "    val_acc_list = []\n",
    "    for n_iter in range(epoch):\n",
    "        loss_batch = []\n",
    "        val_loss_batch = []\n",
    "        velocity = []\n",
    "        for param_layer in net.params:\n",
    "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
    "            velocity.append(p)\n",
    "\n",
    "        # iterate over mini batches\n",
    "        for X_mini, y_mini in minibatches:\n",
    "\n",
    "            loss, grads = net.train_step(X_mini, y_mini)\n",
    "            loss_batch.append(loss)\n",
    "            update(velocity, net.params, grads,\n",
    "                            learning_rate=learning_rate, mu=mu)\n",
    "\n",
    "        for X_mini_val, y_mini_val in minibatches_val:\n",
    "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
    "            val_loss_batch.append(val_loss)\n",
    "\n",
    "\n",
    "        # accuracy of model at end of epoch after all mini batch updates   \n",
    "\n",
    "        if verbose:\n",
    "            m_train = X_train.shape[0]\n",
    "            m_val = X_val.shape[0]\n",
    "            y_train_pred = np.array([], dtype=\"int64\")\n",
    "            y_val_pred = np.array([], dtype=\"int64\")\n",
    "\n",
    "            for i in range(0, m_train, minibatch_size):\n",
    "                X_tr = X_train[i:i + minibatch_size, : ]\n",
    "                y_tr = y_train[i:i + minibatch_size, ]\n",
    "                y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
    "\n",
    "            for i in range(0, m_val, minibatch_size):\n",
    "                X_va = X_val[i:i + minibatch_size, : ]\n",
    "                y_va = y_val[i:i + minibatch_size, ]\n",
    "                y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
    "\n",
    "            train_acc = check_accuracy(y_train, y_train_pred)\n",
    "            val_acc = check_accuracy(y_val, y_val_pred)\n",
    "\n",
    "            mean_train_loss = sum(loss_batch) / float(len(loss_batch))\n",
    "            mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
    "            \n",
    "            train_acc_list.append(train_acc)\n",
    "            val_acc_list.append(val_acc)\n",
    "            \n",
    "            mean_train_loss_list.append(mean_train_loss)\n",
    "            mean_val_loss_list.append(mean_val_loss)\n",
    "\n",
    "            # early stopping with patience = 5 on val loss\n",
    "            if len(val_loss_epoch) == 0:\n",
    "                val_loss_epoch.append(mean_val_loss)\n",
    "            else:\n",
    "                for j in val_loss_epoch[-5:]:\n",
    "                    if mean_val_loss > j:\n",
    "                        c += 1\n",
    "                    else:\n",
    "                        c = 0\n",
    "                if c > 5:\n",
    "                    print('Early stopping')\n",
    "                    return net\n",
    "                else:\n",
    "                    c = 0\n",
    "                    val_loss_epoch.append(mean_val_loss)  \n",
    "                    \n",
    "            if n_iter % draw_each_iters == 0:\n",
    "                clear_output(True)\n",
    "                plot_train_process(train_acc_list, val_acc_list, \n",
    "                                   mean_train_loss_list, mean_val_loss_list)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6. Make a net configuration for training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "f2e0d4811fbb4e7aac64dc8530cb2bc3",
      "ce9cc7f144624d2d8d19ab0299dd1622",
      "9e0dfe4b399641fab241dbd7008d3d55",
      "d4b07093554241c397190154e28677bc",
      "ef66b78a5a5e4275a00acb7401742d34",
      "c1e979ba774c4570abfdee811d3e614c",
      "36161af0cb6742a5a97855a20c603afc",
      "10a84479c0f34526a9e950f20b9feabe",
      "c7ce83e97fc741948c9d462d519ecb95",
      "005bb2f3369c4f9fbe98447a96a9bee2",
      "7fb2de3a19974d31bfeaf306ef14dbca",
      "ac5d05fb85344c1a856d283d32050dda",
      "4b82414d6bbe483c9e80acf3d26a30fe",
      "cfe63fa8547f48fa82ca7de3899b8b88",
      "658c71031d854654b7f5a38ac595b62c",
      "f84498c6f6ba4b1c94689f4f9a5a5bae",
      "74fe8ceaa35e494f95634f2e75bc9512",
      "568c8019d10845b8a198546fc13cda53",
      "4e1f442a81d448fb8f3dbd474d59575f",
      "debf8253ef6c46d9b5169b4827087160",
      "746dd82130554aa09025aaef3f754800",
      "039c1370f3e94750af4f1043b55c3873",
      "33047f6cc3c04a16a565b7877a9f6ab0",
      "c656074689d943b088ebaac2e554d237",
      "91edae2a26894a8fa875301d9ef2f446",
      "a643f4f2e80645dca45e806a5dfd0cf9",
      "f70f9754bfa942e09dd260caa34f2218",
      "9f8600deca6740dc89beba7efc773fd1",
      "90fe170f138f48c7ae12231a0017f226",
      "93b6d0ffb0a74679830ab20abcc2f544",
      "d93a71b79e8c4a25a53a074a1a83c341",
      "92668dbf600d432d8e8602b042bfa5fd",
      "79a6f57619c44f448ae101b3241f3ae2",
      "08e390d49cc04c58bc081b5dc7d9318f",
      "4611478d2042425b8cef04350a8e21be",
      "13a648d0f6754a0794c04581549ad2e7",
      "3ab65e7c23da4c2a9db41169429f846f",
      "109fca0f3427478bb405de77dba936d1",
      "485687f60778428d8633c91ad0b7a9bf",
      "abb3d59e76d14d5d9c4beb2fd2d88fdd",
      "1abc3f2f69924bd5ae966995b109cfd2",
      "79f7f03079784669af002a5724ce226f",
      "167b899c189b45efa8f380a3c31a517f",
      "11e5a9caf30348df808edfb0efb56206",
      "05c73f4e60df4e39b258298d30fc718b",
      "b3b356f3d1254be389d8ceba3d82550f",
      "d8ff006f5e024a35a99f68825193b2e8",
      "87d5e6767d404786af12d4f2f229a457",
      "1bd756cfa3454ee49d364c12ee4bb403",
      "88a60c89e50b470cadfa7ab0b8d4eb40",
      "291b79c7609041749dccb1e91a391f6b",
      "dadb9c3e32af4ae0b40fd71f25efa646",
      "f94e4a0f47f146dcbd230cddca4c9b65",
      "557ae864c1754e58bd83474bf72d81ac",
      "f14171b23f0740c8b242ce3717921f87",
      "4f9592f4d76f4a8e8cc1756a4c62e248",
      "b9270de80cc245f0979a0d0e77901a76",
      "47748544e8404442b8d25a940f576cc8",
      "dc3d47395b9e4bcfa93ce9f235f4c4b4",
      "9a1ff39d2eba4d4cb7f901e26c6bc84d",
      "ae60d1e7829a4ea6a8a1b786eca9f0a3",
      "4e4c7ca2090b4614b23ede92fd5188f8",
      "fff9a800209f4e9091134fce5132ca16",
      "622058abcb874fec899f327591211c5c",
      "8c37df468dca4509897706a11365197a",
      "a0dae47c398d4ce9909aceb111f12867",
      "2f944475bf86437fb4d241ea740de9ad",
      "50449e3073934e9eb2f5da25154bf392",
      "f27513ea8e8c4f3c8a0f770ad7252cc3",
      "b197ae4ea6ce47bfa599aa06572a6a9f",
      "3bd8627fcf4c4e35a48ff8d0dc283194",
      "3ed254bace444ead96d696cda813e594",
      "374c785f1bdf49ffb71220a6fcd7fcad",
      "d3ec56cefa1542b08a9fe0e53872aa0e",
      "1ca69b51869e4cedb338d4fa5806454b",
      "46ea3205a5434475b7cf06a16108aefa",
      "46ac6c9d6c7f4f5fa97fc9b054233e21",
      "8815b9c2259544b3ae5a85a3c39f3e8e",
      "650e70fa6a2c47af95d31e19fc976437",
      "0605b2aa16b446ffa4dbb39089d04d9e",
      "51e877d7b31d4acf9e41c5db602f8a34",
      "d3d190b130d9482e9107ff39e9ee4b22",
      "b72d62cc566e419081f90c68cf769b88",
      "024704d7a6f24c2a909b53bfa7fccdbd",
      "516a600b68d841ab803afd60dfe8ee7e",
      "035339c21fd04814aa04efaedf233dd3",
      "0bc948e524ab4b5684eeb66e20b8ec50",
      "2f12bcd8bab1482eb477e00a83139615",
      "44228e6a58a04630a94d8e7d605f4c59",
      "377810f4f2a645558595db12b1ab91b3",
      "c6d6230f3e7e4ef4b6a4c72597cb4a6a",
      "d4fd4497e3a34071836426fd2ec45f52",
      "3212bacb21c445dc9278064c68043755",
      "c0d6799672a247e886ee1fdb53046a69",
      "9d43fc44ee5e4e9e9d0650cb7aa0b3a5",
      "4488943f3559402c80687733fb2d31e9",
      "43dd410309834648acdc368f7b6af1e9",
      "58794b79a69a43a1ab2b5c70072c78bf",
      "80a64d15496049aa8bf0b5fdcca51f18",
      "041903bd715446b5bd95a661ed207011",
      "e0e2d41131f24b508f71da12b268e1fb",
      "63fefeac3be14b1badcec40b7a101b8f",
      "aafc93b3eff748a4bdeb781fd15334af",
      "a586ccc1b5f2441a9485fba64dc6a4c0",
      "c456e5e66940456b94f6688629f5954c",
      "2989ce71bf254e3b93febc89ac6d29df",
      "f2cfaaecc4874c61bc8f06503f3151df",
      "59aa097870f1476c92d56b5137f5dde7",
      "1cb6fbafbc9947d59d05b3eb29a31281",
      "d065e415e03442309c916d41fc3da5f8",
      "df3fec93631042b78c8db875cce6ce0c",
      "0f919c26e08e4ce587f792de82ee1aad",
      "6cb8f87ff456410e881dd43678997d06",
      "dc7a43c9747b40ef90e9a539a23438e8",
      "3d699b81df634dd68e71930bbb47d823",
      "88cdfd57a72444f4aaa1abee6984830f",
      "20bc0d60e50a4e86a354acc719cc256c",
      "994bb75dbf514d718178bcc1e1dc219d",
      "1cd3bee7a0664dfab6c173a47fcc2aae",
      "8b76efd0cf974020b9bbc379d082c5a8",
      "5b991e77c0744526926d16705b629468",
      "ea23b98acf7646a0a8976b7f18a73765",
      "5c1bca41bb29448686f5d9eb4cff9dee",
      "c35fead9b276474b95c08a01a0897f16",
      "f08f39875e234bffbc8a3664f7deb72b",
      "d1b91673cb624a1095b5890ff632c734",
      "3093df7d73a346ab88cc072237813d69",
      "b606ed7fd87946ceba74c436adc76979",
      "8aff0694f0d94e23bc7ef8a19c7657c8",
      "91cc7674fa6b4e4b8b81254e118dd7fd",
      "d89cea524b3d4a32b67d98523d7c4a9d",
      "ad3f10d1ef18419eaf51307cfa9f471b",
      "2398ce59ba714678879c5bc4b5e30f01",
      "705057a5852a43bf9d8f471b0f1a94db",
      "20922983070444828bb3e1ac625ab9a7",
      "c7b1eae0875f43f4a9f3a7ccf02733d3",
      "b22e6e3f8e4d4e6bab443859fef662ef",
      "b2a4f347805048bbaeb5a30fcf40031b",
      "690854f1ae304e9b891e8d039157106a",
      "5f7bfd2b011845fc86308711fb302aad",
      "e7d62f8f177546a88f87fe4b0088504d",
      "701893f82ad347838d7ccbf845017bfe",
      "5d639f301bb2455c945735ee956311ca",
      "ca0313a3737c4a8b9f860e5383ce6d05",
      "a62ae8a8817042928b7e3df79f1e12e8",
      "b4f918215ab5485c8e3b0905397d554d",
      "b77fc429de2e41c0a8f5f52fbf89dabf",
      "9c36c185a60d4e0f91b0f83c680da246",
      "9c2f62763dc3486f8adab9e1f85f731c",
      "3ee7134dfa8247279e047cef6bc0f809",
      "8da17f3dfe82476b8714ddaea2c1e795",
      "d8c205ae33ff4df6b06b540698080acb",
      "75d5684953564ee5b072f3cfb118a4a2",
      "c590b0c63ebe4cc4add0b0f421893c8a",
      "78e92279c4a84fb79dca8d4bd3db35bd",
      "00f69ee6c21b42e6b611e89fba149987",
      "60e49d15e52444e2a2f406fb216a12cb",
      "b6b3d38d1d7f45c2b7435831e3fb4ef4",
      "d9918b49c6dd4dd38b6472ff2574f20c",
      "b7936c85ff71499997be503e38383bb0",
      "6622fa9a83b04b23aa0392436376a181",
      "4f403cb7b146487baf7c6f8e4ef4655f",
      "94a6841d711140c7a065184cd1e84a90",
      "0a7a1004152940dbb28950a6dcd8b3fc",
      "94029e32e6414b6b9546dfd4b37ba06f",
      "2a525278222e4b51a26a9fbdf48997ca",
      "4e17f2ce5c3d4762b155ac388d39b592",
      "09dc6cc6213e43b4aa13ca23ca187f96",
      "46e2af0450d24fe6b376f5b0962e92dd",
      "14e0e9057d9943f29ac0a38b84d97787",
      "4aa4a3e80fb0471cbd972dd218ec227a",
      "47d32ff8258a4d849f7ace291999dc3f",
      "3809f8ae75df4c35ab691c9a3f02fb3d",
      "800747819c494caba393ffb0efa77d98",
      "5dd9603277dc45cbba9667f1432f0fb5",
      "596241e517214d6c83f4ee452dc7e916",
      "714accca0b82471ab59cb06d5e547868",
      "afab69fcb5804d2db472d11ef6f1f33a",
      "43226a759552422696504f649eb71c59",
      "c97ec4aa15454fe4af329dd09b1ae19e",
      "ce7e34c6a16e453c8a21b34fd8c33491",
      "7ea78e7ff7a347dd831afaa586cf5ee8",
      "424abd034f1345ed8eb5c6b035a55fee",
      "f19abd6efdd64382855cf71d2811676e",
      "4a2f03afc39647aab7dd572f9e031520",
      "7ee9e90e15d747b19bf920b308a52f2d",
      "7462e53ad74c45d78c1d99c9e86ee011",
      "bb52132511074cc7b482cf436c58e5f3",
      "74714147abef448284012ddbc2732c0d",
      "aaa83f09b6fc4ee58010b65cdfc3647f",
      "b4d842bd5dd04025a10658f412138822",
      "a1c07afb72e54b5f87e9abacc1de48e8",
      "2999b302efa84432963eea52baf510d1",
      "53c07064a3724541b8363e60f3ecf092",
      "80a7ebf893ef443f859bf6bd14e3eca5",
      "d0bc47ea70ac4a07b0077f2a85cfe616",
      "3ff619e132a44777be8765d210ba2f4c",
      "8ab428dc9afc492684b85116780b1983",
      "612875939b824adba6b03fd65b4d13dd",
      "132645fe6064437fb9e38128fc12b750"
     ]
    },
    "id": "LEX10Itvi4hH",
    "outputId": "eae0fed2-050b-42ce-9d72-b888e706366e"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get preprocessed training and validation data\n",
    "\n",
    "X_train = np.array([\n",
    "    [1, 2, 1, 2],\n",
    "    [2, 4, 2, 4],\n",
    "    [2, 1, 2, 1],\n",
    "    [4, 2, 4, 2],\n",
    "])\n",
    "\n",
    "y_train = np.array([0, 1, 0, 1])\n",
    "X_val = X_train.copy()\n",
    "y_val = y_train.copy()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "\n",
    "# define neural net\n",
    "model = NN()\n",
    "\n",
    "# add some layers (linear and ReLU)\n",
    "# TODO\n",
    "# YOUR CODE HERE\n",
    "\n",
    "model = train(model, X_train , y_train, minibatch_size=4, epoch=100,\n",
    "           learning_rate=0.1, X_val=X_val, y_val=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guWYUc36i4hH"
   },
   "source": [
    "# Task 7. Make a net configuration for Mnist training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57Zov--yi4hI"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwmHnCEki4hI"
   },
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kq1bvzMAi4hI"
   },
   "outputs": [],
   "source": [
    "y = y.astype(np.int32)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                  test_size=0.25,\n",
    "                                                  shuffle=True,\n",
    "                                                  random_state=0)\n",
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_val = y_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CsgcptQXi4hJ",
    "outputId": "a1c0b8f2-8673-49de-a264-f48ee08fd7f7"
   },
   "outputs": [],
   "source": [
    "# visualize data\n",
    "\n",
    "def vis(img, label):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(label)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "vis_idx = 0\n",
    "vis(X_val[vis_idx].reshape(-1, 28), y_val[vis_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "faf9f36d81854757b17e2d4d3ed2ecd3",
      "0ce32ea4ee0146bb8875e89b4186578e",
      "5d3b302deb014b249edf820b94ab1147",
      "435cc6c512814c549b48417f2965495d",
      "ba6414aed62d4b4e81aab62eaa02cc43",
      "4a7ecad32073492c933e2af256141e38",
      "365709227ac74361bd65120141350699",
      "c2def72ad3d04db39d09c804d063da7c",
      "64fd5ceb705845d4adb1771765192ae6",
      "b873137004c546a1a6f5f71d44d821ea",
      "bc33066297e649f589c99f3ad177cbe6",
      "cc57ebfcaeb448c6ade569b455794ec6",
      "4942a37e8da541c097dbe31929c9cfc4",
      "0a6d7ede816049d3a10d996dd5acc5e1",
      "b46c4c5f53ac459ea5707001545cc329",
      "a9ef30d88b4048599168c98ac57d5839",
      "ccf4daffbe7c44d19916c8f1695d9e3b",
      "775c3c71f3bc4af7b9a7b40f54f80dde",
      "560fe2780bdc40b594793aa88ede84be",
      "703f324201bd48cb8db774f2d9e15017"
     ]
    },
    "id": "cRjpYs43i4hJ",
    "outputId": "58a36cc5-8397-4288-e234-c3fa93f97d3b"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "\n",
    "# define neural net\n",
    "model = NN()\n",
    "\n",
    "# add some layers\n",
    "# YOUR CODE HERE\n",
    "\n",
    "model = train(model, X_train, y_train, minibatch_size=128, epoch=10,\n",
    "           learning_rate=0.001, X_val=X_val, y_val=y_val, draw_each_iters=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTMiMkpEi4hJ",
    "outputId": "5efd1dc6-eb42-4aa1-a8e6-dd53124f84bf"
   },
   "outputs": [],
   "source": [
    "# visualize prediction \n",
    "\n",
    "vis_idx = 23\n",
    "pred = model.predict(X_val[vis_idx])\n",
    "vis(X_val[vis_idx].reshape(-1, 28), pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra* Task 8. Try to make you digit classification better by playing with neural net configuration (accuracy > 90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nn_practice_venv",
   "language": "python",
   "name": "nn_practice_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
